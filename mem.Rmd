% Mixed Effects Models
% Phillip M. Alday
% 05. August 2014


<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br /><span xmlns:dct="http://purl.org/dc/terms/" property="dct:title">Mixed Effects Models</span> by <span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName">Phillip Alday</span> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.

<!-- I make no guarantee about the accuracy or suitability of the content provided herein for any purpose. All code is provided AS IS without any warranty EXPRESSED nor IMPLIED. -->
<!-- I'm a grad student trying to figure some things out and sharing what I think to know. -->

---

```{r setup, include=FALSE}
library(knitr); library(knitcitations)
cite_options(tooltip = TRUE, link = TRUE)
```

## Today's data: Sleep Study
* `Reaction`: RT in ms
* `Days`: day 0 is normal sleep baseline (interval, i.e. Numeric)
* `Subject`: numbered (categorical, non ordinal, i.e. Factor)

## In R
```{r sleepstudy, prompt=TRUE,eval=TRUE}
library(lme4)
data(sleepstudy)
library(lattice) 
str(sleepstudy)
```

## A quick warning
- timeo danaos et dona ferentes!
- Relax, it'll be okay.

# Back to basics

## Statistical Primitives
Basic methods all possible (if tedious) to calculate by hand:

* linear regression (OLS)
* $t$-test
* $F$-test and AN(C)OVA
* $\chi^2$-test, including LR-variant if you have a log-table
* (correlations)

## General linear model
* just about everything in statistics based on the general linear model
* $\chi^2$, $t$-test and its extension factorial ANOVA included 
* $t$-test between groups thus fully equivalent to coefficient tests in linear regression
* ANOVA (F-test) thus fully equivalant to test F-test for overall model fit in linear gression 

## Repeated Measures
* independence assumption violated in repeated measures
* repeated measures ANOVA based on a convenient trick for the special case involving categorial predictors 
* non trivial to extend this trick to ordinal or continuous predictors
* r.m. ANOVA also restricted to modelling repetition in one dimension, while collapsing in all other dimensions
	- traditionally separate $F_1$ (ANOVA by subjects) and $F_2$ (ANOVA by items) to model crossed random effects
	- @clark1973a: combine these two tests into a single measure 
* ANOVA sensitive to unbalanced designs and empty cells

## Impasse
* all the usual stuff can be expressed as a variant of (generalized) linear regression
* except repeated measures ANOVA
* so we have a choice
	- a detailed, full model with lots of subjects and items 
	- or
	- ramming everything into a factorial model

# What happens if we use linear regression on repeated measures data?

## Linear Regression
```{r linreg, prompt=TRUE,eval=TRUE,fig.cap="",tidy=FALSE}
# simple scatter plot
sleep.xy <- xyplot(Reaction ~ Days,data=sleepstudy,
                   xlab = "Days of sleep deprivation",
                   ylab = "Average reaction time (ms)")
```

---

```{r, echo=FALSE,fig.cap=""}
sleep.xy
```

## Make a linear model
* basic line, no error term: $y = mx + b$
* dep = slope*indep + baseline.offset
* outcome = (model) + error


## Fit a line
* Fit a line to observed data with magic and matrices:
    * $Y = \beta_{1}X + \beta_{0} + \epsilon$
    * $Y =  \beta_{2}X + \beta_{1}X + \beta_{0} + \epsilon$
    * $Y =  \beta_{3}X + \beta_{2}X + \beta_{1}X + \beta_{0} + \epsilon$
    * ...
* R has this built in:
    ```{r sleep.lm, prompt=TRUE, eval=TRUE}
    sleep.lm <- lm(Reaction~Days,data=sleepstudy)
    ```
* additional predictors with `+` (no interaction) or `*` (interaction)

## Add a regression line with lattice graphics
```{r linreg-plot, prompt=TRUE, eval=TRUE,fig.cap=""}
# p for points, r for regression
sleep.xy <- update(sleep.xy,type=c("p","r")) 
```

---

```{r, echo=FALSE,fig.cap=""}
sleep.xy
```

## Model summary
\small
```{r sleep.lm.summary, prompt=TRUE, eval=TRUE}
summary(sleep.lm)
```

# Not a great fit!

## Sidebar: ANOVA
\small
```{r sleep.lm.anova, prompt=TRUE, eval=TRUE}
anova(sleep.lm)
```

# But still not a great fit!

## Residuals for all data
```{r linreg-residuals, prompt=TRUE, eval=TRUE,fig.cap=""}
rfs(sleep.lm)
```

## Residuals for a single subject
\tiny
```{r linreg-residuals-vp1, prompt=TRUE, eval=TRUE,fig.cap="",tidy=FALSE}
sleep.lm.vp1 <- lm(Reaction ~ Days,
                   data=sleepstudy[sleepstudy$Subject=="308",])
rfs(sleep.lm.vp1)
```

## Models for single subjects
\tiny
```{r linreg-bysubject, prompt=TRUE, eval=TRUE,fig.cap="",tidy=FALSE}
sleep.xy.bysubj <- xyplot(Reaction ~ Days|Subject,
                          data=sleepstudy,
                          xlab = "Days of sleep deprivation",
                          ylab = "Average reaction time (ms)")
sleep.xy.bysubj
````

## With regression lines
\tiny
```{r linreg-bysubject-lines, prompt=TRUE, eval=TRUE,fig.cap=""}
sleep.xy.bysubj <- update(sleep.xy.bysubj,type=c("p","r"))
sleep.xy.bysubj
```

# What do repeated measures actually do to the data?

## Variance and Repeated Measures
* inter- and intra- variance
* random jitter from our choice of sample population
* each subject fulfills a certain "condition", but random error pro instance of the condition
* similar idea for item analysis in linguistic designs

## Fixed vs Random Effects
Subjects as fixed effect?

* only when we want to make intrasample predictions
* i.e. sample==population
* fixed means known variance / manipulation
* fixed-effects: directed, preferably "exhaustive" manipulation

## Fixed vs Random Effects
Subjects as random effects?

* "random" means unknown variance
* error term is a random effect
* correction for the error resulting from our particular choice of sample
* correction per grouping for slope and intercept possible
* error term per grouping!

## Mixed Effects Models
* "Mixed" because both fixed random effects are used
* Same basic formula syntax `dep ~ indep | group`
* additional `(indep|group)` terms for random effects
```{r sleep.lmer, prompt=TRUE, eval=TRUE,tidy=FALSE}
sleep.lmer <- lmer(Reaction ~ Days + (1|Subject),
                    data=sleepstudy)
```
* More info [here](http://stats.stackexchange.com/questions/18428/formula-symbols-for-mixed-model-using-lme4/61466), [here](http://stats.stackexchange.com/questions/13166/rs-lmer-cheat-sheet/13173), and [here](http://stackoverflow.com/questions/16313109/is-there-a-better-reference-for-r-formulas-than-formula)
```{r formula.help, prompt=TRUE, eval=FALSE,tidy=FALSE}
    ?formula
```

## Model Summary 
\tiny
```{r sleep.lmer.summary, prompt=TRUE, eval=TRUE}
    summary(sleep.lmer)
```

## Model Summary {.allowframebreaks}
```{r, prompt=TRUE, eval=TRUE, echo=FALSE}
    summary(sleep.lmer)
```


## Fixed effect structure
* Package `ez`
    * `ezMixed()` as a convenience for exploring fixed effects
    * `ezPredict()` useful for plotting regression lines
* Package `effects`
* Package `lmerTest`
* Package `languageR`
* Package `LMERConvenienceFunctions`
* Package `lmtest`

## Models
```{r sleep.lmer.fixeff, prompt=TRUE, eval=TRUE,results="hide",tidy=FALSE}
sleep.lmer <- update(sleep.lmer,REML=FALSE)
null <- update(sleep.lmer, . ~ (1|Subject))
```

## Likelihood-ratio test via model comparison
\tiny
``` {r sleep.lmer.lrtest, prompt=TRUE, eval=TRUE}
# can only be used for nested models!
anova(null,sleep.lmer)
```

## Random effect structure
* combine by-subject and by-item analyses in one step
* cf. @clark1973a

## Random effect structure 
* Early idea: build up from minimal structure until improvements don't bring you anything on ANOVA [@baayendavidsonbates2008a]
* New idea: Use the most complicated random effects structure possible [@barrlevyscheepers2013a]

## Random effect structure
Possible random effect structures for ONE fixed factor:

1. Intercepts only by random factor: \linebreak
    `(1 | random.factor)`
2. Slopes only by random factor: \linebreak
    `(0 + fixed.factor | random.factor)`
3. Intercepts and slopes by random factor: \linebreak
    `(1 + fixed.factor | random.factor)`
4. Intercept and slope, separately, by random factor: \linebreak
    `(1 | random.factor) + (0 + fixed.factor | random.factor)`

## Models
\small
```{r sleep.lmer.randeff, prompt=TRUE, eval=TRUE,results="hide",tidy=FALSE}
sleep.lmer.slopes <- update(sleep.lmer, 
							. ~ Days + (1+Days|Subject)) 
sleep.lmer.slopes.int <- update(sleep.lmer,
								. ~ Days + (0+Days|Subject))
```

## Comparing Models
\tiny
``` {r sleep.lmer.anova, prompt=TRUE, eval=TRUE}
    # can only be used for nested models!
    anova(sleep.lmer,sleep.lmer.slopes, sleep.lmer.slopes.int)
```

## Judging Fit
* `anova()` function for `lmer()` provided for convenience and parallel to `lm()`
* $\chi^2$ comparisons valid ONLY for nested models
* use AIC or BIC otherwise
    * no absolute good or bad
    * "smaller is better"
    * hard to determine what a significant difference is
    * [tips](http://stats.stackexchange.com/questions/8557/testing-the-difference-in-aic-of-two-non-nested-models) [on AIC](http://stats.stackexchange.com/questions/25942/will-aic-and-r-square-rank-models-similarly-if-the-number-of-variables-is-equal)
* Use `REML=FALSE` when comparing models!
* More advanced techniques for testing in package [`pbkrtest`](http://cran.r-project.org/web/packages/pbkrtest/index.html)

# relationship to AN(C)OVA

## Relationship to ANOVA
* `ezANOVA()` depends on `aov()` which depends on `lm()`
* `anova()` can be used to compare existing `lm()`s
* linear models compared with $F$ and $t$ tests
* no continuous predictors with ANOVA
* ANOVA works on per-subject item averages and examines variance over subjects for each condition
* MEMs work at an individual trial level and can accomodate empty cells and unbalanced designs!
* `anova()` can be used on individual `lm()`s and `lmer()`s to produce more traditional ANOVA-style output

## ANOVA
```{r}
anova(sleep.lmer.slopes)
```
## ANOVA
\small
```{r}
library(car)
Anova(sleep.lmer.slopes)
```

# Wait, where are the $p$-values?

## [lmer, p-values and all that](https://stat.ethz.ch/pipermail/r-help/2006-May/094765.html)
* degrees of freedom not as trivial as you were led to believe in your basic stats courses 
* not at all clear what a good way is to calculate this in the general case for mixed effects models
* $t$-distribution approximates normal ($z$) distribution for sufficiently high degrees of freedom 
* so treat $t$-values as $z$ values, which are significant at $\alpha = 0.05$ when $|z| > 2$ [cf. @baayendavidsonbates2008a]
* [forget](http://www.johnmyleswhite.com/notebook/2012/05/10/criticism-1-of-nhst-good-tools-for-individual-researchers-are-not-good-tools-for-research-communities/) [$p$-values](http://www.johnmyleswhite.com/notebook/2012/05/12/criticism-2-of-nhst-nhst-conflates-rare-events-with-evidence-against-the-null-hypothesis/) and [traditional notions](http://www.johnmyleswhite.com/notebook/2012/05/14/criticism-3-of-nhst-essential-information-is-lost-when-transforming-2d-data-into-a-1d-measure/) of [significance](http://www.johnmyleswhite.com/notebook/2012/05/18/criticism-4-of-nhst-no-mechanism-for-producing-substantive-cumulative-knowledge/) [behind](http://www.johnmyleswhite.com/notebook/2012/07/17/criticism-5-of-nhst-p-values-measure-effort-not-truth/)! 

## Don't get us started
* focus on estimation, not significance 
* the purely fixed-effects model was able to demonstrate significance of the main effect
* but provided a poor overall description (fit) of the data -- lousy estimate
* this is the foundation of the new statistics [cf. @cummings2014a]
* after all, ["the goal is precision"](http://doingbayesiandataanalysis.blogspot.de/2013/11/optional-stopping-in-data-collection-p.html)

# When things go wrong

## Possible warning messages
* Convergence warnings: you don't have enough data for the proposed model structure
* Singular: perfect multicollinearity (at least one variable is linear combination of the others)
* Not positive definite: matrix not greater than "zero"; too much correlation / collinearity, not enough data

# Generalized linear mixed models (GLMMs) 

## Extensions of linear models to non-linear data
* traditional linear models can be extended to model other types of data such as binary (e.g. yes/no responses)
* basically works by strapping a transformation (link function) onto the front and back ends -- R does this for you!
* fixed effects: `glm()`
* mixed effects: `glmer()`

## Family types
* binomial: (aka logistic regression) `binary ~ continuous`
* Gaussian: (normal linear regression) `continuous ~ continuous` and `continuous ~ categegorial`
* Gamma: `continuous ~ exp(continuous)` (exponential response)
* Poisson: `count ~ continuous`
* (inverse.gaussian, quasi, quasibinomial, quasipoisson)

## Binomial models
* casuality of grouping
    * traditional t-test vs. detection prediction
    * turn the traditional models on their head
* existence / evidence for *a priori* categories 
    * connecting theory and empiry 
    * difficult vs non difficult violations
* `behavioral ~  eeg`
    * performance (cf. `r citet("10.3389/fpsyg.2011.00365")`
    * anomaly detection 
    * Sarah's data

## Even more advanced extensions
* [General additive models](http://www3.nd.edu/~mclark19/learn/GAMS.pdf) extend linear models to arbitrary smooth functions
* Variants also available for mixed effects: generalized additive mixed models, implemented in R with the [`gamm4`](http://cran.r-project.org/web/packages/gamm4/index.html) package

## (More) References {.allowframebreaks}	
* [FAQ](http://glmm.wikidot.com/faq) from the mailing list (lots to absorb at first, but a good place to keep going back to)
* [Stack Exchange](http://stackoverflow.com/) and [Cross Validated](http://stats.stackexchange.com/)
    * [`lmer` Tag](http://stats.stackexchange.com/questions/tagged/lmer)
    * [`mixed model` Tag](http://stats.stackexchange.com/questions/tagged/mixed-model)
    * [`lme4` Tag](http://stackoverflow.com/questions/tagged/lme4)
* [GLM](https://en.wikipedia.org/wiki/Generalized_linear_model) [Families](http://www.statmethods.net/advstats/glm.html)
* Especially relevant questions
    * [Residuals for Binomial GLM](http://stats.stackexchange.com/questions/63566/unexpected-residuals-plot-of-mixed-linear-model-using-lmer-lme4-package-in-r)
    * [Comparing non-nested models](http://stats.stackexchange.com/questions/8513/test-equivalence-of-non-nested-models)
* [Florian Jaeger's blog](http://hlplab.wordpress.com/tag/lmer/)
* [excellent tutorial](http://bodo-winter.net/tutorial/bw_LME_tutorial1.pdf) from Bodo Winter (heed the warning on LR-based approach!)
* Jonathan Harrington (phonetics prof. in Munich):
    * [Mixed Models](http://www.phonetik.uni-muenchen.de/~jmh/lehre/sem/ws1213/Rspeech/mm.pdf) (in German)
    * [Generalized Linear Mixed Models](http://www.phonetik.uni-muenchen.de/~jmh/lehre/sem/ss11/statfort/glmm.pdf) (in English)
* [Tutorial for sociolinguists](http://www2.hawaii.edu/~kdrager/MixedEffectsModels.pdf)
* [lmer, p-values and all that](https://stat.ethz.ch/pipermail/r-help/2006-May/094765.html)
* [Understanding `glmer()`output](https://stat.ethz.ch/pipermail/r-sig-mixed-models/2011q1/015591.html)
* Package `nlme` [(older, more specialized MEM implementation)](http://stats.stackexchange.com/questions/5344/how-to-choose-nlme-or-lme4-r-library-for-mixed-effects-models), see also [here](http://www.opensubscriber.com/message/r-help@stat.math.ethz.ch/5174171.html) and [package comparison](http://glmm.wikidot.com/pkg-comparison)
* Tutorial from `lme4` coauthor: `r citep("http://dx.doi.org/10.1016%2Fj.tree.2008.10.008")`
* Modelling interindividual differences via  mixed models
    * [@klieglweidambacher2010a]
    * [@roehmsoracebornkessel-schlesewsky2012a]
* In corpus linguistics / dialectology: [@wielingnerbonnebaayen2011a]

## More Academic Bibliography {.allowframebreaks}
```{r, echo=FALSE, results='asis'}
#print("placeholder")
# bibliography("html")
```
